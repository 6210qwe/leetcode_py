# -*- coding:utf-8 -*-
# ============================================================================
# 题目信息
# ============================================================================
"""
题号: 217
标题: Contains Duplicate
难度: easy
链接: https://leetcode.cn/problems/contains-duplicate/
题目类型: 数组、哈希表、排序
"""

# ============================================================================
# 问题描述
# ============================================================================
"""
217. 存在重复元素 - 给你一个整数数组 nums 。如果任一值在数组中出现 至少两次 ，返回 true ；如果数组中每个元素互不相同，返回 false 。 示例 1： 输入：nums = [1,2,3,1] 输出：true 解释： 元素 1 在下标 0 和 3 出现。 示例 2： 输入：nums = [1,2,3,4] 输出：false 解释： 所有元素都不同。 示例 3： 输入：nums = [1,1,1,3,3,4,3,2,4,2] 输出：true 提示： * 1 <= nums.length <= 105 * -109 <= nums[i] <= 109
"""

# ============================================================================
# 实现思路
# ============================================================================
"""
核心思想: 使用集合（set）记录已出现的元素，如果遇到重复元素返回True

算法步骤:
1. 创建一个集合
2. 遍历数组，如果元素已在集合中，返回True
3. 否则将元素加入集合
4. 遍历结束返回False

关键点:
- 使用集合快速查找
- 时间复杂度O(n)，空间复杂度O(n)
"""

# ============================================================================
# 复杂度分析
# ============================================================================
"""
时间复杂度: O(n) - 需要遍历数组一次
空间复杂度: O(n) - 集合存储元素
"""

# ============================================================================
# 代码实现
# ============================================================================

from typing import List
from leetcode_solutions.utils.solution import create_solution


def contains_duplicate(nums: List[int]) -> bool:
    """
    函数式接口 - 存在重复元素
    
    实现思路:
    使用集合（set）记录已出现的元素，如果遇到重复元素返回True。
    
    Args:
        nums: 整数数组
        
    Returns:
        如果存在重复元素返回True，否则返回False
        
    Example:
        >>> contains_duplicate([1, 2, 3, 1])
        True
    """
    seen = set()
    for num in nums:
        if num in seen:
            return True
        seen.add(num)
    return False


# 自动生成Solution类（无需手动编写）
Solution = create_solution(contains_duplicate)
